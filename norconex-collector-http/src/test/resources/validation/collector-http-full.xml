<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE xml>
<!-- 
   Copyright 2017-2019 Norconex Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- This is a config file with as many configuration options being set
     as possible, to test validation as much we can.
     -->
<httpcollector id="Test Collector HTTP Config">

  <progressDir>/progress</progressDir>
  <logsDir>/logs</logsDir>

  <crawlerDefaults>
    <startURLs stayOnDomain="true" includeSubdomains="true" stayOnPort="true" stayOnProtocol="true">
      <url>http://www.example.com</url>
      <url>http://www.sample.com</url>
      <urlsFile>/local/path/to/a/file/full/of/urls.txt</urlsFile>
      <sitemap>http://www.somewhere.com/sitemap.xml</sitemap>
      <provider class="com.norconex.collector.http.crawler.MockStartURLsProvider"/>
    </startURLs>
    <keepDownloads>true</keepDownloads>
    <keepOutOfScopeLinks>false</keepOutOfScopeLinks>
    <maxDepth>99</maxDepth>
    <numThreads>1</numThreads>
    <workDir>/tmp/111</workDir>
    <maxDocuments>111</maxDocuments>
    <orphansStrategy>PROCESS</orphansStrategy>
    <crawlerListeners>
      <listener class="com.norconex.collector.http.crawler.event.impl.URLStatusCrawlerEventListener">
        <statusCodes>404</statusCodes>
        <outputDir>/tmp/path</outputDir>
        <fileNamePrefix>broken-links</fileNamePrefix>
      </listener>
    </crawlerListeners>
    <userAgent>Please identify your Crawler</userAgent>
    <urlNormalizer disabled="false" class="com.norconex.collector.http.url.impl.GenericURLNormalizer">
      <normalizations>
        lowerCaseSchemeHost, upperCaseEscapeSequence, 
        decodeUnreservedCharacters, removeDefaultPort 
      </normalizations>
      <replacements>
        <replace><match>A</match><replacement>B</replacement></replace>
        <replace><match>C</match></replace>
      </replacements>
    </urlNormalizer>
    <delay class="com.norconex.collector.http.delay.impl.GenericDelayResolver"
          default="1s" ignoreRobotsCrawlDelay="true" scope="crawler" >
      <schedule dayOfWeek="from Monday to Friday"
          dayOfMonth="from 1 to 10" time="from 8:00 to 16:30">10s</schedule>
      <schedule dayOfWeek="from Saturday to Sunday"
          dayOfMonth="from 11 to 28" time="from 6:00 to 7:30">20000</schedule>
    </delay>    
    <crawlDataStoreFactory class="com.norconex.collector.http.data.store.impl.mongo.MongoCrawlDataStoreFactory">
      <host>localhost</host>
      <port>1234</port>
      <dbname>dbName</dbname>
      <username>user</username>
      <password>pwd</password>
    </crawlDataStoreFactory>
    <httpClientFactory class="com.norconex.collector.http.client.impl.GenericHttpClientFactory">
      <cookiesDisabled>true</cookiesDisabled>
      <connectionTimeout>1</connectionTimeout>
      <socketTimeout>2 minutes</socketTimeout>
      <connectionRequestTimeout>3 min 30s</connectionRequestTimeout>
      <connectionCharset>asdf</connectionCharset>
      <expectContinueEnabled>true</expectContinueEnabled>
      <maxRedirects>4</maxRedirects>
      <localAddress>address</localAddress>
      <maxConnections>5</maxConnections>
      <maxConnectionsPerRoute>6</maxConnectionsPerRoute>
      <maxConnectionIdleTime>7</maxConnectionIdleTime>
      <maxConnectionInactiveTime>8</maxConnectionInactiveTime>
      <trustAllSSLCertificates>true</trustAllSSLCertificates>
      <disableSNI>true</disableSNI>
      <sslProtocols>item1,item2</sslProtocols>
      <proxyHost>host</proxyHost>
      <proxyPort>9</proxyPort>
      <proxyRealm>realm</proxyRealm>
      <proxyScheme>scheme</proxyScheme>
      <proxyUsername>username</proxyUsername>
      <proxyPassword>pwd</proxyPassword>
      <proxyPasswordKey>key</proxyPasswordKey>
      <proxyPasswordKeySource>environment</proxyPasswordKeySource>
      <authFormParams>
        <param name="token1"></param>
        <param name="token2">somevalue2</param>
      </authFormParams>
      <headers>
        <header name="head1"></header>
        <header name="head2">value2</header>
      </headers>
      <authMethod>digest</authMethod>
      <authUsername>user</authUsername>
      <authPassword>pass</authPassword>
      <authPasswordKey>thekey</authPasswordKey>
      <authPasswordKeySource>file</authPasswordKeySource>
      <authUsernameField>userfield</authUsernameField>
      <authPasswordField>pwdfield</authPasswordField>
      <authURL>authURL</authURL>
      <authFormCharset>authCharset</authFormCharset>
      <authHostname>authHost</authHostname>
      <authPort>9</authPort>
      <authRealm>authRealm</authRealm>
      <authWorkstation>authWorkstation</authWorkstation>
      <authDomain>authDomain</authDomain>
      <authPreemptive>true</authPreemptive>
    </httpClientFactory>
    <referenceFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </referenceFilters>    
    <robotsTxt ignore="false" class="com.norconex.collector.http.robot.impl.StandardRobotsTxtProvider"/>
    <sitemapResolverFactory ignore="false" lenient="true" 
        class="com.norconex.collector.http.sitemap.impl.StandardSitemapResolverFactory">
      <tempDir>/tmp/</tempDir>
      <path>/path1/</path>
      <path>/path2/</path>
    </sitemapResolverFactory>
    <redirectURLProvider class="com.norconex.collector.http.redirect.impl.GenericRedirectURLProvider"
        fallbackCharset="UTF-8" />
    <recrawlableResolver class="com.norconex.collector.http.recrawl.impl.GenericRecrawlableResolver"
             sitemapSupport="last" >
         <minFrequency applyTo="reference" caseSensitive="false" value="always" >
             .*\.pdf
         </minFrequency>
         <minFrequency applyTo="contentType" caseSensitive="true" value="3000" >
             text/html
         </minFrequency>
    </recrawlableResolver>
    <metadataFetcher class="com.norconex.collector.http.fetch.impl.GenericMetadataFetcher" >
      <validStatusCodes>200,123</validStatusCodes>
      <notFoundStatusCodes>404,456</notFoundStatusCodes>
      <headersPrefix>prefix</headersPrefix>
    </metadataFetcher>
    <metadataFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexMetadataFilter"
          onMatch="include" caseSensitive="false" field="title">Blah.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </metadataFilters>
    <canonicalLinkDetector class="com.norconex.collector.http.url.impl.GenericCanonicalLinkDetector"
          ignore="true">
      <contentTypes>text/html</contentTypes>
    </canonicalLinkDetector>
    <metadataChecksummer 
        class="com.norconex.collector.http.checksum.impl.LastModifiedMetadataChecksummer"
        disabled="false" keep="true" targetField="myfield" />    
    <documentFetcher class="com.norconex.collector.http.fetch.impl.GenericDocumentFetcher"
        detectContentType="true" detectCharset="true">
      <validStatusCodes>200,123</validStatusCodes>
      <notFoundStatusCodes>404,456</notFoundStatusCodes>
      <headersPrefix>prefix</headersPrefix>
    </documentFetcher>
    <robotsMeta ignore="false" 
       class="com.norconex.collector.http.robot.impl.StandardRobotsMetaProvider">
       <headersPrefix>prefix</headersPrefix>
    </robotsMeta>
    <linkExtractors>
      <extractor class="com.norconex.collector.http.url.impl.GenericLinkExtractor"
          maxURLLength="999" ignoreNofollow="false" 
          commentsEnabled="true" charset="UTF-8" >
        <contentTypes>text/html</contentTypes>
        <schemes>https</schemes>
        <tags>
          <tag name="a" attribute="href" />
          <tag name="frame" attribute="src" />
          <tag name="iframe" attribute="src" />
          <tag name="img" attribute="src" />
          <tag name="meta" attribute="http-equiv" />
        </tags>
        <extractBetween caseSensitive="true">
          <start>start1</start><end>end1</end>
        </extractBetween>
        <extractBetween caseSensitive="false">
          <start>start2</start><end>end2</end>
        </extractBetween>
        <noExtractBetween caseSensitive="true">
          <start>nostart1</start><end>noend1</end>
        </noExtractBetween>
        <noExtractBetween caseSensitive="false">
          <start>nostart2</start><end>noend2</end>
        </noExtractBetween>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.GenericLinkExtractor">
        <tags>
          <tag name="a" attribute="href" />
          <tag name="script" attribute="src" />
        </tags>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.RegexLinkExtractor"
          maxURLLength="1234" charset="asdf">
        <applyToContentTypePattern>ct.*</applyToContentTypePattern>
        <applyToReferencePattern>ref.*</applyToReferencePattern>
        <linkExtractionPatterns>
          <pattern><match>\[(.*?)\]</match><replace>$1</replace></pattern>
          <pattern><match>http://.*?\.html</match></pattern>
        </linkExtractionPatterns>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.XMLFeedLinkExtractor">
          <applyToContentTypePattern>.*</applyToContentTypePattern>
          <applyToReferencePattern>.*</applyToReferencePattern>
      </extractor>      
    </linkExtractors>
    <documentFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexMetadataFilter"
          onMatch="include" caseSensitive="false" field="title">Blah.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </documentFilters>
    <preImportProcessors>
      <processor class="com.norconex.collector.http.processor.impl.FeaturedImageProcessor">
         <pageContentTypePattern>text/html</pageContentTypePattern>
         <domSelector>dom dom</domSelector>
         <minDimensions>425x312</minDimensions>
         <largest>true</largest>
         <imageCacheSize>1234</imageCacheSize>
         <imageCacheDir>/some/path</imageCacheDir>
         <storage>url, inline</storage>
         <scaleQuality>medium</scaleQuality>
         <scaleDimensions>25</scaleDimensions>
         <scaleStretch>true</scaleStretch>
         <imageFormat>gif</imageFormat>
         <storageDiskDir structure="datetime">/some/other/path</storageDiskDir>
         <storageDiskField>diskField</storageDiskField>
         <storageInlineField>inlineField</storageInlineField>
         <storageUrlField>urlField</storageUrlField>
      </processor>      
    </preImportProcessors>

    <!-- Importer is purposely slim since the full config is tested in
         Importer project. -->
    <importer>
      <preParseHandlers>
        <transformer class="com.norconex.importer.handler.transformer.impl.ReplaceTransformer">
          <replace><fromValue>A</fromValue><toValue>B</toValue></replace>
        </transformer>  
      </preParseHandlers>
      <postParseHandlers>
        <transformer class="com.norconex.importer.handler.transformer.impl.ReplaceTransformer">
          <replace><fromValue>C</fromValue><toValue>D</toValue></replace>
        </transformer>  
      </postParseHandlers>    
    </importer>

    <documentChecksummer 
        class="com.norconex.collector.core.checksum.impl.MD5DocumentChecksummer"
        disabled="false" keep="true" targetField="afield">
      <sourceFields>field1,field2</sourceFields>
    </documentChecksummer>
    <postImportProcessors>
      <processor class="com.norconex.collector.http.processor.impl.MockHttpDocumentProcessor"/>
    </postImportProcessors>    
    <spoiledReferenceStrategizer 
        class="com.norconex.collector.core.spoil.impl.GenericSpoiledReferenceStrategizer"
        fallbackStrategy="DELETE">
      <mapping state="NOT_FOUND" strategy="DELETE" />
      <mapping state="BAD_STATUS" strategy="DELETE" />
      <mapping state="ERROR" strategy="IGNORE" />
    </spoiledReferenceStrategizer>

    <committer class="com.norconex.committer.core.impl.FileSystemCommitter">
      <directory>/tmp/somepath</directory>
    </committer>

  </crawlerDefaults>
  
  <crawlers>
    <crawler id="myCrawler1">
      <numThreads>2</numThreads>
      <workDir>/tmp/222</workDir>
      <maxDocuments>222</maxDocuments>
      <orphansStrategy>DELETE</orphansStrategy>
    </crawler>
    <crawler id="myCrawler2">
      <numThreads>3</numThreads>
      <workDir>/tmp/333</workDir>
      <maxDocuments>333</maxDocuments>
      <orphansStrategy>IGNORE</orphansStrategy>
    </crawler>
  </crawlers>


</httpcollector>